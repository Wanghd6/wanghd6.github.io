<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>cvpr review | HeidiWang</title><meta name="author" content="HeidiWang"><meta name="copyright" content="HeidiWang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="introductionwhat is CV?goal of CVto write computer programs that can interpret images&#x2F;videos input:images or videosoutput:description of the worldlow level visionmeasurements enhancement region segmen">
<meta property="og:type" content="article">
<meta property="og:title" content="cvpr review">
<meta property="og:url" content="http://example.com/2024/05/06/cvpr%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/index.html">
<meta property="og:site_name" content="HeidiWang">
<meta property="og:description" content="introductionwhat is CV?goal of CVto write computer programs that can interpret images&#x2F;videos input:images or videosoutput:description of the worldlow level visionmeasurements enhancement region segmen">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Wanghd6/imgbed/master/tao.jpg">
<meta property="article:published_time" content="2024-05-06T04:23:24.157Z">
<meta property="article:modified_time" content="2024-05-06T04:45:08.001Z">
<meta property="article:author" content="HeidiWang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Wanghd6/imgbed/master/tao.jpg"><link rel="shortcut icon" href="/img/new-hd.png"><link rel="canonical" href="http://example.com/2024/05/06/cvpr%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"TQ7IDV7WMN","apiKey":"05892f2cb7b80665162f2aa1a232dfbd","indexName":"my-hexo-blog","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: HeidiWang","link":"链接: ","source":"来源: HeidiWang","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'cvpr review',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-05-06 12:45:08'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/tao.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">2</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/poi/"><i class="fa-fw fas fa-music"></i><span> POI</span></a></li><li><a class="site-page child" href="/paper/"><i class="fa-fw fas fa-video"></i><span> 经典论文</span></a></li><li><a class="site-page child" href="/cv/"><i class="fa-fw fas fa-music"></i><span> CV</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raw.githubusercontent.com/Wanghd6/imgbed/master/banner-1571866_1280.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="HeidiWang"><span class="site-name">HeidiWang</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/poi/"><i class="fa-fw fas fa-music"></i><span> POI</span></a></li><li><a class="site-page child" href="/paper/"><i class="fa-fw fas fa-video"></i><span> 经典论文</span></a></li><li><a class="site-page child" href="/cv/"><i class="fa-fw fas fa-music"></i><span> CV</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">cvpr review</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-05-06T04:23:24.157Z" title="发表于 2024-05-06 12:23:24">2024-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-05-06T04:45:08.001Z" title="更新于 2024-05-06 12:45:08">2024-05-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/CV/">CV</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="cvpr review"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><h2 id="what-is-CV"><a href="#what-is-CV" class="headerlink" title="what is CV?"></a>what is CV?</h2><h3 id="goal-of-CV"><a href="#goal-of-CV" class="headerlink" title="goal of CV"></a>goal of CV</h3><pre><code>to write computer programs that can interpret images/videos
</code></pre><h3 id="input-images-or-videos"><a href="#input-images-or-videos" class="headerlink" title="input:images or videos"></a>input:images or videos</h3><h3 id="output-description-of-the-world"><a href="#output-description-of-the-world" class="headerlink" title="output:description of the world"></a>output:description of the world</h3><h3 id="low-level-vision"><a href="#low-level-vision" class="headerlink" title="low level vision"></a>low level vision</h3><pre><code>measurements
enhancement
region segmentation
features
</code></pre><h3 id="mid-level-vision"><a href="#mid-level-vision" class="headerlink" title="mid level vision"></a>mid level vision</h3><pre><code>reconstruction
depth
motion estimation
</code></pre><h3 id="high-level-vision"><a href="#high-level-vision" class="headerlink" title="high level vision"></a>high level vision</h3><pre><code>category detection
activity recognition
deep understandings
</code></pre><h2 id="what-is-recognition"><a href="#what-is-recognition" class="headerlink" title="what is recognition"></a>what is recognition</h2><h3 id="identificaiton-of-a-pattern-as-a-memeber-of-a-class-we-already-know-or-we-are-familiar-with"><a href="#identificaiton-of-a-pattern-as-a-memeber-of-a-class-we-already-know-or-we-are-familiar-with" class="headerlink" title="identificaiton of a pattern as a memeber of a class we already know , or we are familiar with"></a>identificaiton of a pattern as a memeber of a class we already know , or we are familiar with</h3><p>2 type of recognition<br>calssification-supervised learning<br>classes are known<br>clustering-unsupervised learning<br>classes are unknown</p>
<h2 id="what-is-PR"><a href="#what-is-PR" class="headerlink" title="what is PR"></a>what is PR</h2><h3 id="PR-is-a-brunch-of-machine-learning"><a href="#PR-is-a-brunch-of-machine-learning" class="headerlink" title="PR is a brunch of machine learning"></a>PR is a brunch of machine learning</h3><p>focuses on the recognition of patterns and regularities in data</p>
<h3 id="PR-is-a-process-of"><a href="#PR-is-a-process-of" class="headerlink" title="PR is a process of"></a>PR is a process of</h3><p>analyzing and dealing with various information<br>charactering the objects or phenomenon<br>providing their descriptions,identifications ,classifications anf interpretations</p>
<h3 id="PR-is-the-study-of-how-machine-can"><a href="#PR-is-the-study-of-how-machine-can" class="headerlink" title="PR is the study of how machine can"></a>PR is the study of how machine can</h3><p>observe the enviroment(percive)<br>learn to distinguish the pattern of interest from their beckground(process)<br>make sound and resonable decisions about classes of pattenrs(prediction)</p>
<h3 id="PR-classifies-“pattern”-into-classes"><a href="#PR-classifies-“pattern”-into-classes" class="headerlink" title="PR classifies “pattern” into classes"></a>PR classifies “pattern” into classes</h3><h3 id="PR-intends-to"><a href="#PR-intends-to" class="headerlink" title="PR intends to"></a>PR intends to</h3><p>quantify and favor a simple classifier<br>automatically determine that a simple curve is preferable to an even simpler straight line or a complicated boundary<br>predict how well the system will generalize to a new patterns</p>
<h3 id="what-is-ML"><a href="#what-is-ML" class="headerlink" title="what is ML"></a>what is ML</h3><p>ML is a study of algorithms to improves their performance at specific task with experiments</p>
<h3 id="ML-is-an-interdiscilinary-field-of"><a href="#ML-is-an-interdiscilinary-field-of" class="headerlink" title="ML is an interdiscilinary field of"></a>ML is an interdiscilinary field of</h3><p>the mathmatical foundations<br>practical applications of system<br>learning, reasoning and acting</p>
<h3 id="supervised-learning"><a href="#supervised-learning" class="headerlink" title="supervised learning"></a>supervised learning</h3><p>a set of training data with known class labels<br>SL is to lean to sign the correct class label for a new input<br>unsupervised learning<br>a set of traning data and features vectors<br>to lean their underlying similarities<br>clustering similar class together<br>semi supervised learning<br>we can access to rather limited number of labeled data<br>unsupervised learning with a prior knowledge<br>reinforcement learning<br>we only get feedback in the form of how well we are doing<br>to learn to act in the way to maxmize rewards in the long term</p>
<h2 id="challenge"><a href="#challenge" class="headerlink" title="challenge"></a>challenge</h2><p>viewpoint variation<br>illumination<br>occlusion<br>scale<br>deformation<br>background clutter<br>object intra-class variation<br>local ambiguity<br>the world behind the image</p>
<h1 id="Feature-extraction-and-matching"><a href="#Feature-extraction-and-matching" class="headerlink" title="Feature extraction and matching"></a>Feature extraction and matching</h1><p>local features<br>properties of local features<br>locality<br>features are local,so robust to occlusion and clutter<br>quantity<br>hundreds or thousands in a single image<br>distinctiveness<br>can differentiate a large database of objection<br>efficiency<br>real-time performance achievable<br>find features invariant (geomatric 、photometirc)to transformation<br>approaches:<br>feature detection<br>feature descriptor<br>feature matching<br>feature tracking<br>main components:<br>detecion<br>description<br>matching<br>what makes a good feature<br>uniqueness<br>local measures of uniqueness<br>flat region:no change in all direction<br>edge region:no change along the edge direction<br>corner：significant change in all directions<br>Feature detection:<br>shifting the window $W$ by $(u,v)$<br>define an sum of squared difference (SSD)error<br>$ E(u,v)=\sum_{(x,y) \in W}^{} \left [ I(x+u,y+v)-I(x,y) \right ] ^2 $<br>利用泰勒展开<br>let $I_{x}=\frac{\partial I}{\partial x} $ and $I_{y}=\frac{\partial I}{\partial y}$<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240502101903.png" alt=""><br>an SSD error $E(u,v)$<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240502104225.png" alt=""><br>其中，<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240502105517.png" alt=""><br>$E(u,v)$is locally approximated as a quadratic error function<br>Horizontal edge:$I_x=0,H = \begin{bmatrix} 0 &amp;0 \\ 0 &amp;C\end{bmatrix}$<br>Vertical edge:$I_y=0,H = \begin{bmatrix} A &amp;0 \\ 0 &amp;0\end{bmatrix}$<br>Eigenvalues and eigenvectors of H:<br>Define shift directions with the smallest and largest change in error<br>$x_{max}$=direction of the largest increase in $E$<br>$\lambda_{max}$= amount of increase in direction $x_{max}$<br>$x_{min}$= direciton o the smallest increse in $E$<br>$\lambda_{min}=amount of increse in direction $x_{min}$<br>$Hx_{max}=\lambda_{max}x_{max}$<br>$Hx_{min}=\lambda_{min}x_{min}$<br>classification of image points using eigenvualues of $H$<br>edge:$\lambda_{2}&gt;&gt;\lambda_{1}$ or $\lambda_{1}&gt;&gt;\lambda_{2} $<br>flat:l1 and l2 are small;E is almost constant in all directions<br>Corner:$\lambda_{1}$ and $\lambda_{2}$ are large,$\lambda_{1} \sim \lambda_{2}$, $E$ increase in all directions<br>corner detection:<br>Compute the gradient at each point in the image<br>Create the $H$ matrix from the entries in the gradient<br>Compute the eigenvalues<br>Find points with large response ($\lambda_{max} &gt; threshold$)<br>Choose those points where $\lambda_{min}$ is a local maximum as features<br>harris operator:<br>$\lambda_{min}$ is a variant of the “harris operator”for feature detection<br>$f = \farc{\lambda_{1}\lambda_{2}}{\lambda_{1}+\lambda_{2}}=\frac{determination(H)}{trace(H)}$<br>The $trac$ is the sum of diagonals,$trace(H)=h_{11}+h_{22}=A+C<br>very similar to $\lambda_{min}$ but less expensive<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240502154206.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240502155533.png" alt=""><br>feature description<br>image transformations:<br>geometric rotation<br>geometric scale<br>photometric intensity change<br>we want corner locations to be<br>invariant to photometric transformations<br>quivariant to geometric transformations<br>invariance:<br>corner locations do not change even if image is transformed<br>Equivariance:<br>if we have two tasnformed versions of the same image,feature should be  detected in corresponding locations<br>image translation<br>derivatives and windows function are equivariant<br>Corner location is equivariant w.r.t translation<br>image rotation<br>second moment ellipse rotates its shape(eigenvalues) remains the same<br>Corner location is equivariant w.r.t. rotation<br>affine intensity chang(仿射强度变化):$I \rightarrow aI + b$<br>only derivatives are used<br>intensity scaling $I \rightarrow aI$<br>Partially invariant to affine intensity change<br>scaling:<br>Neither invariant nor equivariant to scaling<br>scale invariant detection:<br>key idea：find scale that gives local maximum of $f$ in both position and scale<br>one definition of $f$ :the harris operator<br>automatic scale selection:<br>computing $f$ for a larger and larger windows<br>using a fixed window size with gaussian pyramid<br>feature extraction:corners and blobs<br>another definition of $f$:laplacian of gaussian<br>Similar to a Difference of Gaussians (DoG)<br>Gaussian minus a slightly smaller Gaussian<br>laplacian of guassian = “blob” detector<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240502210059.png" alt=""><br>feature mathcing<br>Invariance vs Discriminability:<br>Invariance: Descriptor shouldn’t change even if image is transformed<br>Discriminability: Descriptor should be highly unique for each point<br>Invariant descriptors<br>designed to be invariant to translation, 2D rotation, and scale<br>most feature desciptor can usually also handle:<br>Limited 3D rotations<br>Limited affine transforms<br>Limited illumination/contrast changes<br>How to achieve invariance<br>Make sure the detector is invariant<br>Design an invariant feature descriptor<br>Multiscale Oriented PatcheS descriptor<br>Scale Invariant Feature Transform (SIFT)<br>HOG: Histogram of Gradient<br>FREAK: Fast Retina Keypoint<br>LIFT: Learned Invariant Feature Transform<br>Keypoint detection: repeatable and distinctive<br>Corners, blobs, stable regions<br>Harris, DoG<br>Descriptors: robust and selective<br>spatial histograms of orientation<br>SIFT and variants are typically good for stitching<br>and recognition but, need not stick to one<br>Given a feature in an image $I_{1}$, how to find the best match in $I_{2}$,<br>Define distance function that compares two descriptors<br>Test all the features in $I_{2}$,, find the one with min distance<br>How to define the difference between teo features $f_{1}$ and $f_{2}$<br>Better approach: ratio distance =$ \frac{\left|f_{1}-f_{2}\right|}{\left|f_{1}-f_{2}^{\prime}\right|}$<br>$f_{2}$ is the best SSD match to $f_{1}$ in $I_{2}$<br>$f_{2}^{\prime}$ is the 2nd best SSD match to $f_{1}$ in $I_{2}$<br>Gives large values for ambiguous matches<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240502234229.png" alt=""></p>
<h1 id="Classification-using-Bayes-Decision-Theory"><a href="#Classification-using-Bayes-Decision-Theory" class="headerlink" title="Classification using Bayes Decision Theory"></a>Classification using Bayes Decision Theory</h1><h2 id="Bayes-decision-theory"><a href="#Bayes-decision-theory" class="headerlink" title="Bayes decision theory"></a>Bayes decision theory</h2><p>statistic method for pattern recognition<br>fundamentals of most pattern recognition algorithms<br>basic assumption<br>the decision problem is posed in probabilistic terms<br>all relevant probability values are known<br>decision before observation<br>problem: make a decision where prior probability $P(\omega) is known<br>No observation is allowed<br>Bayes formula:<br>$P\left(\omega_{j} \mid x\right)=\frac{p\left(x\mid \omega_{j}\right) P\left(\omega_{j}\right)}{p(x)}$<br>$posterior = \frac{likelihood \times prior}{evidence}$<br>likelihood :class-conditional PDF,$p(x|\omega_{j})where $1 \le j \le c$<br>prior probability$P(\omega_{j})<br>evidence:unconditional density of $x$, $ {\textstyle \sum_{}^{}} p(x)=\sum_{j=1}^{c} p\left(x \mid \omega_{j}\right) P\left(\omega_{j}\right)$<br>unknown posterior probability, $p(w_{j} \mid x)<br>Bayes decision rule:<br>if $P(\omega_{j}\mid x)&gt;P(\omega \ mid x) ,\forall i \ne j \Rightarrow $ decide $\omega_{j}$<br>$P(\omega_{j})$ and $p(x \mid \omega_{j}) are assumed to be konwn<br>$p(x)$ is irrelevant to Bayesian decisioin<br>$p(x)$ is a normalization factorand unrelated to any class<br>special case 1:<br>euqal prior probability :$P(\omega_{1})=P(\omega_{2})=…P(\omega_{c})= \frac{1}{c}$<br>depends on the likelihood $p(x \mid \omega_{j})$<br>special case 2:<br>equal likelihood $p(x \mid \omega_{1}) = p(x \mid \omega_{2}=…=p(x \mid \omega_{c})$<br>reverse back to naive decision rule<br>Bayes decision rule (for classes c=2)<br>if $P(\omega_{1}|x)&gt;P(\omega_{2}|x)$ , decide $\omega_{1}$ , otherwise , decide $\omega_{2}$<br>equivalently, if $p(x\mid \omega_{1})P(\omega_{1})&gt;p(x \mid \omega_{2})P(\omega_{2})$ , decide $\omega_{1}$ , otherwise $\omega_{2}$<br>for euiprobable classes:$P(\omega_{1}) = P(\omega_{2})$<br>if $p(x\mid \omega_{1})&gt;p(x \mid \omega_{2})$ , decide $\omega_{1}$ , otherwise $\omega_{2}$<br>Example1:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503150123.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503150217.png" alt=""><br>Example2:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503165958.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503170405.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503170445.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503170652.png" alt=""><br>Loss function<br>Whenever we observe a particular $x$ , the probability of errror is:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503172715.png" alt=""><br>using Bayes decision rule:<br>$P(error \mid x)=min[P(\omega_{1}\mid x),P(\omega_{2}\mid x)]<br>For each $x$, $P(error \mid x)$ should be as small as possible<br>average probability of error should be as small as possible for all possible $x$<br>Bayesian classifier is optimal with respect to minimizing the classification error probability!!!<br>A loss funcion is more general than probability of error , $\lambda(\alpha _i \ mid \omega_{j}),the loss of taking action $\alpha_{i}$ when the class is $\omega _j$<br>where:<br>more than one feature:<br>$x \in R \Rightarrow \in R^{d} $ (d-dimensional Euclidean space)<br>c classes(state of nature): $\Omega \in {\omega _1,\omega _2,…\omega _c}$<br>actions(instead of only deciding the class):$\mathcal{A} = \left \{   \alpha_1,\alpha_2,…\alpha_{a}\right \}$(finite set of a possible actions, $a \ne c$ )<br>Expected loss(conditional risk)<br>$R(\alpha_i \mid x) = \sum_{j=1}^{c} \lambda (\alpha_i \mid \omega _j)P(\omega _j \mid x)$<br>$\lambda (\alpha_i \mid \omega _j)$:the incurred loss of taking action $\alpha _i$ in the true class $\omega _j$<br>$P(\omega _j \mid x)$: the probability of $\omega _j$ being the true class of $x$<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503220605.png" alt=""><br>Task(general case) :<br>to find a mapping from patterns to actions:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503221322.png" alt=""><br>Overall risk R:<br>$R = \int R(\alpha (x)\mid x)p(x)dx$<br>where $p(x)$: pdf of patterns ,and<br>$R(\alpha (x)\mid x)p(x):$ conditional risk of pattern $x$ with action $\alpha(x)$<br>it is the expected loss with decision function $\alpha ()$ ;<br>for every $x$, conditional risk $R(\alpha (x) \mid x) must be as small as possible<br>the overall risk for all possible $x$ must be as small as possible<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503223636.png" alt=""><br>Special case :two-category classification<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503224428.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503224625.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503225203.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503225428.png" alt=""><br>example:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503225928.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503225959.png" alt=""><br>Minimum-Error-Rate classification<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503230442.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503230624.png" alt=""><br>Discriminant functions<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503231510.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503231547.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503231704.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503231828.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503232053.png" alt=""><br>Bayesian Classification for Normal Distributions<br>normal/Gaussian distribution:multivariate case<br>$X \sim N(\mu , \Sigma ):$<br>$p(X) = \frac{1}{(2 \pi)^{\frac{d}{2}}\left | \Sigma \right | ^{\frac{1}{2}}}exp\left [ -\frac{1}{2}(X-\mu)^{T}\Sigma ^{-1}(X- \mu) \right ] $<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240503233740.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504004114.png" alt=""><br>example(2-dimensional case):<br>$X \sim N(\mu , \Sigma ):$<br>$p(X) = \frac{1}{(2 \pi)\left | \Sigma \right | ^{\frac{1}{2}}}exp\left [ -\frac{1}{2}(x_1-\mu_{1})(x_2-\mu_{2})^{T}\Sigma ^{-1}\begin{pmatrix}x_1 - \mu_{1} \\x_2 - \mu_{2}\end{pmatrix} \right ] $<br>where<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504004933.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504010408.png" alt=""><br>case 1:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504011512.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504012052.png" alt=""><br>case 2:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504012426.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504012637.png" alt=""><br>case 3:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504012748.png" alt=""><br>Minimum Distance Classifiers<br>$P(\omega_{i})=\frac{1}{c}$, equiprobable<br>$g_{i}(x)=-\frac{1}{2}(x-\mu_{i})^{T}\Sigma_{i}^{-1}(x-\mu_{i})$<br>$\Sigma_{i}=\sigma^{2}I$:<br>assign $x \rightarrow \omega_{i}$ , small Euclidean Distance: $d_{E} \equiv \left | x-\mu_{i} \right | $<br>$\Sigma_{i}=\Sigma$:<br>assign $x \rightarrow \omega_{i}$ , small Mahalanobis Distance: $d_{m} \equiv \sqrt{(x-\mu_{i})^{T}\Sigma^{-1}(x-\mu_i)} $<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504014621.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504014659.png" alt=""></p>
<h1 id="Estimation-Methods"><a href="#Estimation-Methods" class="headerlink" title="Estimation Methods"></a>Estimation Methods</h1><p>Parameter Estimation<br>$P(\omega_{j} \ mid x)=\frac{p(x \mid \omega_{j})P(\omega_{j})}{p(x)}$ $1 \leq j \leq c$ (bayes formula)<br>likelihood $p(x \mid \omega_{j})$ and Prior probability $P(\omega_{j})$<br>unkown<br>eatimateed from training samples(supervised learning)<br>collect training samples $X = {x_1 , x_2,… x_N}$ distributed according to $p(x \mid \omega_{j})$<br>$x_1 , x_2,… x_N$ are i.i.d<br>For prior probability $P(\omega_{j})$<br>$P(w_{j}) = \frac{\left | x_{j} \right | }{ {\textstyle \sum_{i=1}^{N}}\left | x_{i} \right | }$<br>where $\left | x \right |$ is the number of elements in $x$<br>Estimation under parametric form : $p(x \mid \omega_{j} , \theta_{j})<br>Maximum-likelihood(ML) estimation<br>consider parameters as fixed but unknown quantities<br>estimate parameters by maximizing likelihood of observing actual training examples<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504133526.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504165739.png" alt=""><br>ML estimation of $\hat{\theta} $<br>$\hat{\theta_{ML}}:\hat{\frac{\partial L(\theta)}{\partial \theta} } = 0$<br>namely , $\hat{\theta_{ML}}:\sum_{k=1}^{N} \frac{\partial \ln p\left(x_{k} \mid \theta\right)}{\partial \theta}=0$<br>case 1:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504174432.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504175352.png" alt=""><br>case 2:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504183834.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504184057.png" alt=""><br>for multivariates case:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504184231.png" alt=""><br>Bayes estimation<br>consider parameters as random variables with some known prior distribution<br>we look $\theta$ as an unknown random vector, described by a PDF $p(\theta)$<br>Given $X = {x_1 , x_2 ,…,x_N}$ , we compute the maximum of $p(\theta \mid X)$<br>observing the actual training examples transforms the parameters’ prior distribution into posterior distribution using Bayes formula<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504190701.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504190735.png" alt=""><br>example:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504191446.png" alt=""></p>
<h1 id="Dimension-Reducion"><a href="#Dimension-Reducion" class="headerlink" title="Dimension Reducion"></a>Dimension Reducion</h1><h2 id="dimension-reduction"><a href="#dimension-reduction" class="headerlink" title="dimension reduction"></a>dimension reduction</h2><p>changes the data representation into a low-dimensional one<br>preserve the data structure<br>is usually unsupervised</p>
<h3 id="why-dimension-reduction"><a href="#why-dimension-reduction" class="headerlink" title="why dimension reduction"></a>why dimension reduction</h3><p>computation complexity<br>The computation complexity grows exponentially with the data dimension<br>pre_processing stage before further learning<br>data visulization<br>Projection of high-dimensional data to 2D or 3D<br>2D/3D plots of data make nice pictures<br>data interpretation<br>recovering the intrinsic dimensionality of the data<br>Some data features may be irrelevant<br>Application:<br>Pattern recognition and analysis<br>Digital image and speech processing<br>Gene expression microarray data<br>Visualization of large networks<br>Methods:<br>Principal component analysis (PCA)Independent component analysis (ICA)<br>Linear discriminant analysis (LDA)<br>Locally linear embedding (LLE)<br>Linear discriminant embedding (LDE)<br>Canonical correlation analysis (CCA)</p>
<h2 id="Singular-Value-Decomposition-SVD"><a href="#Singular-Value-Decomposition-SVD" class="headerlink" title="Singular Value Decomposition (SVD)"></a>Singular Value Decomposition (SVD)</h2><p>SVD definition<br>$A_{m \times n}=U_{m \times m}S_{m \times n}V^{T}_{n \times n}<br>A is any $m \times n$ matrix<br>U is any $m \times n$ orthogonal matrix<br>正交矩阵：$UU^{T}=U^{T}U=1$,$U^{T}=U^{-1}$<br>S is any $m \times n$ diagonal matrix<br>V is any $m \times n$ orthogonal matrix<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504203139.png" alt=""><br>Singular values $\omega_1 &gt; |omega_2 &gt;…&gt;\omega_n &gt;0$ 沿着S的主对角线以降序出现<br>$\omega_{1}^{2} &gt; |omega_{2}^{2} &gt;…&gt;\omega_{n}^{2} $ are the eigenvalues of $AA^{T}$ and $A^{T}A$<br>Calculation procedures of SVD<br>Step 1: Calculate $AA^{T}$ and $A^{T}A$<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504203702.png" alt=""><br>Step 2: Eigenvalues and S<br>根据$\left | AA^{T}-\lambda I \right | =0$算出$\lambda$以及它的正平方根$\theta$,根据$\theta$得出矩阵S<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504203731.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504205132.png" alt=""><br>Step 3: Finding U<br>根据$(AA^{T}-\lambda I )x =0$算出对应的$x$，并单位化后得到向量$u$,根据$u$得出矩阵U<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504210552.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504210615.png" alt=""><br>Step 4: Finding V<br>与setp 3 步骤相同，但根据$(A^{T}A-\lambda I )x =0$进行计算<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504211055.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504211106.png" alt=""><br>Step 5: Complete SVD<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504211951.png" alt=""></p>
<h2 id="Principle-Component-Analysis-PCA"><a href="#Principle-Component-Analysis-PCA" class="headerlink" title="Principle Component Analysis (PCA)"></a>Principle Component Analysis (PCA)</h2><p>PCA:<br>Performs a linear projection of the data to a lower-dimensional space<br>Maximizes the data variance in the low-dimensional representation<br>A simple and non-parametric method of extracting relevant information from confusing data<br>Straightforward way on how to reduce a complicate data set to a<br>lower dimension<br>problem formulation:<br>Reduce the data set from n-dimensions to k-dimensions<br>Find k vectors $u^{(1)},u^{(2)} …u^{(k)}$<br>Project the data to minimize the projection error<br>data preprocessing:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504233655.png" alt=""><br>reduce data feom n-dimensions to k-dimensions<br>comupute covariance matrix<br>$\Sigma=\frac{1}{m} \sum_{i=1}^{m} x^{(i)}\left(x^{(i)}\right)^{T}=\frac{1}{m} X X^{T}$<br>compute eigenvectors of matrix $\Sigma$ using matlab function svd or eig<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504234515.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504235810.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504235919.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240504235933.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505000007.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505000635.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505000910.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505001158.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505001315.png" alt=""></p>
<h2 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h2><p>PCA:<br>finds the most accurate data representation in a lower dimensional space<br>projects data i nthe directions of maximum variance<br>problem:<br>the directions of maximum variance may be useless for classification<br>LDA:<br>is called Fisher Linear discriminant analysis<br>projects data to the direction useful for data classification<br>objective:<br>LDA reduces data dimensionality while preserving the discriminative information<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505003359.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505003528.png" alt=""><br>sample means of each class in x-sapce and y-sapce:<br>$\mu_i = \frac{1}{N_i}\sum_{x \in \omega_i}x$<br>$\hat{\mu}_i = \frac{1}{N_i}\sum_{y \in \omega_i}y=\frac{1}{N_i}\sum_{y \in \omega_i}w^{T}x=w^{T}\mu_i$<br>distance between projected means is :<br>\left | \tilde{\mu}_1- \tilde{ \mu}_2 \right | =\left | w^{T}(\mu_1-\mu_2) \right |<br>It ignores the standard deviation within classes<br>Fisher’s solution is to maximize the difference between the means, normalized by a measure of the within-class scatter<br>scatter is equivalent of the variance of each class:<br>$\tilde{s}_{i}^{2} = \sum_{y \in \omega_i}(y-\tilde{\mu}_i)^2$<br>the within-class scatter of the projected samples:$(tilde{s}_{1}^{2}+tilde{s}_{2}^{2})<br>the criterion function<br>$J(w)=\frac{\left | \tilde{\mu}_1- \tilde{ \mu}_2 \right |^{2}}{tilde{s}_{1}^{2}+tilde{s}_{2}^{2}}<br>Fisher linear discriminant is defined as a linear function $w^{T}x$ that maximizes the criterion function $J(W)$<br>LDA seeks for a projection allowing：<br>samples from the same class are very close to each other<br>projected means are as farther apart as possible<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505010733.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505010841.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505010904.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505011018.png" alt=""><br>example：<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505011728.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505011843.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505012051.png" alt=""></p>
<h1 id="Support-Vector-Machines"><a href="#Support-Vector-Machines" class="headerlink" title="Support Vector Machines"></a>Support Vector Machines</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Supervised learning algorithm for classification and regression<br>Derived from statistical learning theory<br>Exceptional performance in handwritten digital recognition</p>
<h3 id="philosiphy"><a href="#philosiphy" class="headerlink" title="philosiphy"></a>philosiphy</h3><p>Finding an optimized separating hyperplane to maximize margins<br>Converting problem to the dual problem<br>Allowing for errors in classificaiton using “slack variables”<br>Using kernel mapping for better linear separation of nonlinearly separable data<br>A kernel is like using an infinite number of features<br>Given two linearly separable classes , each hyperplane is characterized by :<br>$f(x)=w^{T}x + b = 0$<br>its direction in sapce,$w$<br>its position in space, $b$<br>SVMs use a single hyperplane to distinguish 2 classes , it has many possible solutions .<br>Hypeplane maximizes the margin is better .<br>Support vector:<br>a subset of training samples<br>samples closest to hyperplane<br>the most difficulty to classify<br>Distance from each sample $x_i$ to the hyperplane is<br>$r = \frac{w^{T}x_{i}+b}{\left | w \right | }$<br>$w$ is the weight vector<br>$b$ is the bias<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505122010.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505122330.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505122508.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505123205.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505123255.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505125909.png" alt=""><br>support vectors are the closest vectors for each class to the classifier $w^{T}x_i + b = \pm 1$<br>The optimal hyperplane classifier of a support vector machine is unique.<br>The quadratic optimization problem<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505135727.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505135934.png" alt=""><br>This dual problem is a convex quadratic programming (QP)<br>problem<br>Global maximum of $\lambda_{i}$ can always be found<br>Well established tools for solving this optimization problem<br>The solution involves constructing a dual problem<br>Lagrange multiplier $\lambda_{i}$ is associated with every inequality<br>constraint in the original problem<br>Given a solution $\lambda_{1},\lambda_{2},…lambda_{N}$ to the dual problem,solution to the original problem is:<br>$w = \sum_{i=1}^{N}\lambda_{i}y_{i}x_{i}$<br>$b = y_k -\sum_{i=1}{N}\lambda_{i}w^{T}x_{k}$ , $\forall \lambda_{k} &gt; 0$<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505160024.png" alt=""><br>Soft Margin Classification<br>Non-separable Classes<br>There is no hyperplane satisfying $y_{i}\left(w^{T} x+b\right)&gt;1 \quad \forall x$<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505160515.png" alt=""><br>Slack variables $\xi_{i} ≥ 0$<br>$y_i(w^{T}x+b) ≥ 1 − \xi_i$<br>Samples outside the margin<br>(correctly classified): $\xi_i = 0$<br>Margin Violation: $0 &lt; \xi_i \le 1$<br>Misclassified samples: $\xi_i &gt;1$<br>$\xi_i$ allows misclassification of difficult or noisy samples<br>Resulting margin is called soft margin<br>$\xi_i$ is based on the output of the<br>discriminant function $w^{T}x+b$<br>$\xi_i$ approximates the number of<br>misclassified samples<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505171142.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505171516.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505171844.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505171855.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505172056.png" alt=""><br>Nonelinear SVM<br>Linear SVM<br>The classifier is a separating hyperplane<br>Most important training points are support vectors<br>Support vectors define the hyperplane<br>Quadratic optimization algorithms can identify which training points<br>$x_i$ are support vectors with non-zero Lagrangian multipliers $\lambda_i$<br>Non-linear SVM<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505182243.png" alt=""><br>General idea:<br>The original feature space can always be mapped to some higherdimensional feature space $\Phi (x)$where the training set is separable.<br>Possible transformation problems:<br>High computation burden due to high dimensionality<br>Hard to obtain a good estimation<br>SVM solves these two issues simultaneously<br>Kernel tricks for efficient computation<br>Minimize $\left | w \right | ^{2}$ can lead to a “good” classifier<br>kernel funcion<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505214348.png" alt=""><br>kernel example<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505220129.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505221238.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505221343.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505221614.png" alt=""><br>SVM properties:<br>Flexibility in choosing a similarity function<br>Sparseness of solution when dealing with large data sets<br>Only support vectors are used to specify the separating hyperplane<br>Ability to handle large feature spaces<br>Complexity does not depend on the dimensionality of the feature space<br>Overfitting can be controlled by soft margin approach<br>SVM properties (Cont.)<br>Nice path property: a simple convex optimization problem<br>Guarantee to converge to a single global solution<br>Feature selection<br>SVM applications<br>hand-written character recognition<br>image classification<br>Bioinformatics<br>Protein classification<br>Cancer classification</p>
<h1 id="Perceptron-and-Neural-Networks"><a href="#Perceptron-and-Neural-Networks" class="headerlink" title="Perceptron and Neural Networks"></a>Perceptron and Neural Networks</h1><h2 id="Perceptron-Algorithm"><a href="#Perceptron-Algorithm" class="headerlink" title="Perceptron Algorithm"></a>Perceptron Algorithm</h2><p><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505225028.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505225219.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505230603.png" alt=""><br>Our goal: compute a solution, a hyperplane $w$, so that<br>$w^{T}x + w_{0} &gt; 0 (or &lt; 0),$ $x \in \omega_{1}(or \omega_{2})<br>Perceptron algorithm:<br>Defines a cost function<br>Chooses an algorithm to minimize the cost function<br>The minimum corresponds to a solution<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505232705.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240505232842.png" alt=""><br>example:<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240506000322.png" alt=""><br>The perceptron algorithm is a reward and punishment scheme<br>if $w^{T}x + w_{0} &gt; 0$, assign $x \in \omega_{1}$<br>if $w^{T}x + w_{0} &lt; 0$, assign $x \in \omega_{2}$<br>XOR problem:<br>AND and  OR operations are linearly separable<br>For XOR problem , draw two-lines , This is a two-phase design.<br>Two-Layer Perceptron:<br>Phase 1: draw two-lines (hyperplanes)<br>$g_1(x) = g_2(x) = 0$<br>Each one is realized by a perceptron<br>Depending on the position of $x$, the outputs of perceptrons are<br>$y_{i}=f\left(g_{i}(x)\right)=\left\{\begin{array}{l}0 \\1\end{array}\right.$<br>Phase 2: find the position of x w.r.t both lines<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240506095136.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240506100242.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240506100903.png" alt=""><br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240506104157.png" alt=""><br>Two-layer perceptron<br>The output neuron realizes a hyperplane in the transformed space<br>The hyperplane separates some vertices from the others<br>It has the capability to classify vectors into classes that consist of<br>unions of polyhedral regions<br>However, not any union, It depends on the relative position of the<br>corresponding vertices<br>Three-layer perception<br>It can classify vectors into classes consisting of ANY union of<br>polyhedral regions<br>The idea is similar to the XOR problem<br>It realizes more than one planes in the $y \in R^{p} $space.<br>1st layer forms the hyperplanes<br>2nd layer forms the regions<br>output neuron forms the classes<br>Output neuron realizes an OR gate<br>For each vertex with class A, construct a hyperplane to leaves it on one side (+) and ALL others to the other side (-)<br>Ways to design multilayer perceptrons are developing a<br>structure<br>to classify correctly all the training patterns<br>OR to compute the synaptic weights to optimize a cost function<br><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/20240506111228.png" alt=""></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">HeidiWang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/05/06/cvpr%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/">http://example.com/2024/05/06/cvpr%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">HeidiWang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/Wanghd6/imgbed/master/tao.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2024/04/28/hello-world/" title="Hello World"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hello World</div></div></a></div></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="comment-switch"><span class="first-comment">Valine</span><span id="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raw.githubusercontent.com/Wanghd6/imgbed/master/tao.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">HeidiWang</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">2</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Wanghd6/wanghd6.github.io"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Wanghd6" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:18856308712@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎光临小站，这里是我对日常的整理总结，希望对你有所帮助:)</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text">introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#what-is-CV"><span class="toc-number">1.1.</span> <span class="toc-text">what is CV?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#goal-of-CV"><span class="toc-number">1.1.1.</span> <span class="toc-text">goal of CV</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#input-images-or-videos"><span class="toc-number">1.1.2.</span> <span class="toc-text">input:images or videos</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#output-description-of-the-world"><span class="toc-number">1.1.3.</span> <span class="toc-text">output:description of the world</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#low-level-vision"><span class="toc-number">1.1.4.</span> <span class="toc-text">low level vision</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mid-level-vision"><span class="toc-number">1.1.5.</span> <span class="toc-text">mid level vision</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#high-level-vision"><span class="toc-number">1.1.6.</span> <span class="toc-text">high level vision</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-is-recognition"><span class="toc-number">1.2.</span> <span class="toc-text">what is recognition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#identificaiton-of-a-pattern-as-a-memeber-of-a-class-we-already-know-or-we-are-familiar-with"><span class="toc-number">1.2.1.</span> <span class="toc-text">identificaiton of a pattern as a memeber of a class we already know , or we are familiar with</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-is-PR"><span class="toc-number">1.3.</span> <span class="toc-text">what is PR</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PR-is-a-brunch-of-machine-learning"><span class="toc-number">1.3.1.</span> <span class="toc-text">PR is a brunch of machine learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PR-is-a-process-of"><span class="toc-number">1.3.2.</span> <span class="toc-text">PR is a process of</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PR-is-the-study-of-how-machine-can"><span class="toc-number">1.3.3.</span> <span class="toc-text">PR is the study of how machine can</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PR-classifies-%E2%80%9Cpattern%E2%80%9D-into-classes"><span class="toc-number">1.3.4.</span> <span class="toc-text">PR classifies “pattern” into classes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PR-intends-to"><span class="toc-number">1.3.5.</span> <span class="toc-text">PR intends to</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#what-is-ML"><span class="toc-number">1.3.6.</span> <span class="toc-text">what is ML</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ML-is-an-interdiscilinary-field-of"><span class="toc-number">1.3.7.</span> <span class="toc-text">ML is an interdiscilinary field of</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#supervised-learning"><span class="toc-number">1.3.8.</span> <span class="toc-text">supervised learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#challenge"><span class="toc-number">1.4.</span> <span class="toc-text">challenge</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Feature-extraction-and-matching"><span class="toc-number">2.</span> <span class="toc-text">Feature extraction and matching</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Classification-using-Bayes-Decision-Theory"><span class="toc-number">3.</span> <span class="toc-text">Classification using Bayes Decision Theory</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Bayes-decision-theory"><span class="toc-number">3.1.</span> <span class="toc-text">Bayes decision theory</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Estimation-Methods"><span class="toc-number">4.</span> <span class="toc-text">Estimation Methods</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dimension-Reducion"><span class="toc-number">5.</span> <span class="toc-text">Dimension Reducion</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#dimension-reduction"><span class="toc-number">5.1.</span> <span class="toc-text">dimension reduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#why-dimension-reduction"><span class="toc-number">5.1.1.</span> <span class="toc-text">why dimension reduction</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Singular-Value-Decomposition-SVD"><span class="toc-number">5.2.</span> <span class="toc-text">Singular Value Decomposition (SVD)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Principle-Component-Analysis-PCA"><span class="toc-number">5.3.</span> <span class="toc-text">Principle Component Analysis (PCA)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LDA"><span class="toc-number">5.4.</span> <span class="toc-text">LDA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Support-Vector-Machines"><span class="toc-number">6.</span> <span class="toc-text">Support Vector Machines</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivation"><span class="toc-number">6.1.</span> <span class="toc-text">Motivation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#philosiphy"><span class="toc-number">6.1.1.</span> <span class="toc-text">philosiphy</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Perceptron-and-Neural-Networks"><span class="toc-number">7.</span> <span class="toc-text">Perceptron and Neural Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Perceptron-Algorithm"><span class="toc-number">7.1.</span> <span class="toc-text">Perceptron Algorithm</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/06/cvpr%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/" title="cvpr review">cvpr review</a><time datetime="2024-05-06T04:23:24.157Z" title="发表于 2024-05-06 12:23:24">2024-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/04/28/hello-world/" title="Hello World">Hello World</a><time datetime="2024-04-28T05:27:09.764Z" title="发表于 2024-04-28 13:27:09">2024-04-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !true) {
    if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><script>(() => {
  const disqus_config = function () {
    this.page.url = 'http://example.com/2024/05/06/cvpr%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/'
    this.page.identifier = '/2024/05/06/cvpr%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/'
    this.page.title = 'cvpr review'
  }

  const disqusReset = () => {
    window.DISQUS && window.DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  btf.addGlobalFn('themeChange', disqusReset, 'disqus')

  const loadDisqus = () =>{
    if (window.DISQUS) disqusReset()
    else {
      const script = document.createElement('script')
      script.src = 'https://.disqus.com/embed.js'
      script.setAttribute('data-timestamp', +new Date())
      document.head.appendChild(script)
    }
  }

  const getCount = async() => {
    try {
      const eleGroup = document.querySelector('#post-meta .disqus-comment-count')
      if (!eleGroup) return
      const cleanedLinks = eleGroup.href.replace(/#post-comment$/, '')

      const res = await fetch(`https://disqus.com/api/3.0/threads/set.json?forum=&api_key=&thread:link=${cleanedLinks}`,{
        method: 'GET'
      })
      const result = await res.json()

      const count = result.response.length ? result.response[0].posts : 0
      eleGroup.textContent = count
    } catch (err) {
      console.error(err)
    }
  }

  if ('Valine' === 'Disqus' || !true) {
    if (true) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
    else {
      loadDisqus()
      GLOBAL_CONFIG_SITE.isPost && getCount()
    }
  } else {
    window.loadOtherComment = loadDisqus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.22.1/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4.65.0/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js?v=4.13.0"></script></div></div></body></html>